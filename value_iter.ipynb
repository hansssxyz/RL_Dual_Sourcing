{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dd5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook explores the optimal Reinforcement Learning steady state policy given a fixed poisson demand\n",
    "# by using markov chain properties and value iterations. \n",
    "# This is used as a benchmark to see how well our actor critic Agent performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca1ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /var/folders/_x/fh3t8wcj3_xbs4fddcxmbpc00000gn/T/matplotlib-2akz9u6e because the default path (/Users/hansshen/.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from dual_sourcing_game import DualSourcing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ce4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class value_iter:\n",
    "    def __init__(self,dual_sourcing_env,lr,delta_prob_matrix=0.01,delta_val=0.1):\n",
    "        self.env=dual_sourcing_env\n",
    "        self.lr=lr\n",
    "        #state_space[0]=[-max_inven,[0]*rl,[0]*el],[1]=[-max_inven,[0]*rl,[0]*(el-1)+[1]]\n",
    "        self.state_space_dim=(self.env.max_inventory*2+1)*(self.env.max_order+1)**(self.env.rl+self.env.el)\n",
    "        self.action_space_dim=self.state_space_dim*(self.env.max_order+1)**(2)\n",
    "        self.markov_matrix=[[0]*self.action_space_dim for _ in range(self.state_space_dim)]\n",
    "        #delta_prob_matrix is the error term associated with the markov matrix\n",
    "        total_prob=0\n",
    "        X=0\n",
    "        demand=[]\n",
    "        while(1-total_prob>delta_prob_matrix):\n",
    "            prob=np.exp(-self.env.poisson_lambda)*np.power(self.env.poisson_lambda,X)/np.math.factorial(X)\n",
    "            demand.append([prob,self.env.fixed_demand+X])\n",
    "            total_prob+=prob\n",
    "            X+=1\n",
    "        self.demand=demand\n",
    "        \n",
    "            \n",
    "    #auxiliary function:\n",
    "    #converting between index in state_space and [inventory,reg pipeline vector,exp pipeline vector] format\n",
    "    def state_index(self,state):\n",
    "        index=(state[0]+self.env.max_inventory)*(self.env.max_order+1)**(self.env.rl+self.env.el)\n",
    "        index+=sum(state[1][i]*(self.env.max_order+1)**(self.env.el+self.env.rl-1-i) for i in range(self.env.rl))\n",
    "        index+=sum(state[2][i]*(self.env.max_order+1)**(self.env.el-i-1) for i in range(self.env.el))\n",
    "        return index\n",
    "    def state_representation(self,index):\n",
    "        inv=index//((self.env.max_order+1)**(self.env.rl+self.env.el))-self.env.max_inventory\n",
    "        index=index%((self.env.max_order+1)**(self.env.rl+self.env.el))\n",
    "        reg_orders=[0]*self.env.rl\n",
    "        for i in range(self.env.rl):\n",
    "            reg_orders[i]=index//(self.env.max_order+1)**(self.env.el+self.env.rl-1-i)\n",
    "            index=index%(self.env.max_order+1)**(self.env.el+self.env.rl-1-i)\n",
    "        exp_orders=[0]*self.env.el\n",
    "        for i in range(self.env.el):\n",
    "            exp_orders[i]=index//(self.env.max_order+1)**(self.env.el-i-1)\n",
    "            index=index%(self.env.max_order+1)**(self.env.el-i-1)\n",
    "        return [inv,reg_orders,exp_orders]\n",
    "    def generate_state(self):\n",
    "        return self.generate_state_driver(self,[],[list(range(-self.))])\n",
    "    def generate_state_driver(self,cur,data):\n",
    "        if not data:\n",
    "            yield cur\n",
    "        else:\n",
    "            for elem in data[0]:\n",
    "                for rest in self.generate_state_driver(cur,data[1:])\n",
    "                    yield [elem]+rest\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b9b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'regular_leadtime':3,'express_leadtime':1,'regular_cost':3,'express_cost':4,\"max_order\":3,\"max_inventory\":10,\n",
    "       'store_cost':2.6,'back_cost':5,'y':0.95,'starting_state':[5,[0 for _ in range(3)],[0 for _ in range(1)]]}\n",
    "game=DualSourcing(config,episode_len=5000)\n",
    "v=value_iter(game,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618ef62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
